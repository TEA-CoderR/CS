import csv
import random
import time
from datetime import datetime, timedelta
from playwright.sync_api import sync_playwright

# ========== å¯é€‰ä»£ç†ï¼ˆå¦‚ä½ å¯ç”¨ä½å®…ä»£ç†ï¼‰==========
PROXIES = [
    # "http://username:password@proxy1.com:port"
]

# ========== æ¨¡æ‹Ÿè®¾ç½®ZIPï¼ˆåœ°åŒºï¼‰ ==========
# def set_zip_code(page, zipcode="10001"):
#     try:
#         page.goto("https://www.amazon.com/", timeout=60000, wait_until="networkidle")
#         page.click("#nav-global-location-popover-link", timeout=10000)
#         page.fill("#GLUXZipUpdateInput", zipcode, timeout=10000)
#         page.click("#GLUXZipUpdate")
#         page.wait_for_timeout(5000)
#         print(f"âœ… ZIP Code å·²è®¾ç½®ä¸º {zipcode}")
#     except Exception as e:
#         print(f"âš ï¸ è®¾ç½®ZIPå¤±è´¥: {e}")
def set_zip_code(page, zipcode="10001"):
    try:
        page.goto("https://www.amazon.com/", timeout=60000, wait_until="domcontentloaded")
        page.wait_for_selector("#nav-global-location-popover-link", timeout=15000)
        page.click("#nav-global-location-popover-link", timeout=10000)

        page.wait_for_selector("#GLUXZipUpdateInput", timeout=10000)
        page.fill("#GLUXZipUpdateInput", zipcode)
        page.click("#GLUXZipUpdate", timeout=5000)

        # æœ‰æ—¶ä¼šå¼¹å‡ºç¡®è®¤æŒ‰é’®
        try:
            page.wait_for_selector("input[name='glowDoneButton']", timeout=5000)
            page.click("input[name='glowDoneButton']")
        except:
            pass

        page.wait_for_timeout(5000)
        print(f"âœ… ZIP Code å·²è®¾ç½®ä¸º {zipcode}")
    except Exception as e:
        print(f"âš ï¸ è®¾ç½®ZIPå¤±è´¥: {e}")


# ========== æŠ“å–å•†å“ä¿¡æ¯ ==========
def get_amazon_product_info(sku_url, proxy=None):
    with sync_playwright() as p:
        browser_args = {}
        if proxy:
            browser_args['proxy'] = {"server": proxy}
        # browser = p.chromium.launch(headless=True, **browser_args)
        browser = p.chromium.launch(headless=False, slow_mo=100)

        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            locale="en-US",
            extra_http_headers={
                "Accept-Language": "en-US,en;q=0.9"
            }
        )

        page = context.new_page()

        try:
            set_zip_code(page, zipcode="10001")  # è®¾ç½®åœ°åŒºä¸ºçº½çº¦
            page.goto(sku_url, timeout=60000, wait_until="domcontentloaded")
        except Exception as e:
            browser.close()
            return {"ä»·æ ¼": "N/A", "åº“å­˜æƒ…å†µ": "N/A", "é¢„è®¡åˆ°è´§": "N/A", "æŠ“å–å¤±è´¥": True, "é”™è¯¯ä¿¡æ¯": str(e)}

        try:
            price = page.query_selector('span.a-price span.a-offscreen').inner_text()
        except:
            price = "N/A"

        try:
            stock = page.query_selector('#availability span').inner_text()
        except:
            stock = "N/A"

        try:
            eta = page.query_selector('#mir-layout-DELIVERY_BLOCK span.a-text-bold').inner_text()
        except:
            eta = "N/A"

        browser.close()
        return {
            "ä»·æ ¼": price,
            "åº“å­˜æƒ…å†µ": stock,
            "é¢„è®¡åˆ°è´§": eta,
            "æŠ“å–å¤±è´¥": False
        }

# ========== è¾…åŠ©è§£æ ==========
def parse_price(price_str):
    try:
        return float(price_str.replace('$', '').replace(',', '').strip())
    except:
        return None

def parse_stock(stock_str):
    if stock_str.lower().startswith("only"):
        try:
            return int(stock_str.split(" ")[1])
        except:
            return 0
    elif "unavailable" in stock_str.lower():
        return 0
    return 100

def parse_eta(eta_str):
    try:
        eta_date = datetime.strptime(eta_str.strip(), "%A, %B %d")
        eta_date = eta_date.replace(year=datetime.now().year)
        return eta_date
    except:
        return None

# ========== åˆ¤æ–­æ˜¯å¦é—®é¢˜SKU ==========
def is_problematic(item, fetched_info):
    problems = []
    if fetched_info.get("æŠ“å–å¤±è´¥", False):
        problems.append(f"æŠ“å–å¤±è´¥: {fetched_info.get('é”™è¯¯ä¿¡æ¯', 'æœªçŸ¥é”™è¯¯')}")
        return True, problems

    current_price = parse_price(fetched_info["ä»·æ ¼"])
    local_price = parse_price(item["æœ¬åœ°å±•ç¤ºä»·"])
    stock_num = parse_stock(fetched_info["åº“å­˜æƒ…å†µ"])
    eta_date = parse_eta(fetched_info["é¢„è®¡åˆ°è´§"])
    now = datetime.now()
    late_threshold = now + timedelta(days=6)

    if !stock_num or stock_num < 10:
        problems.append(f"åº“å­˜è¿‡ä½ï¼ˆ{stock_num}ï¼‰")
    if current_price and local_price and (current_price * 2 > local_price):
        problems.append(f"è´§æºæ¶¨ä»·ï¼ˆå½“å‰: {current_price}, æœ¬åœ°: {local_price}ï¼‰")
    if eta_date and eta_date > late_threshold:
        problems.append(f"åˆ°è´§æ—¶é—´è¿‡é•¿ï¼ˆ{fetched_info['é¢„è®¡åˆ°è´§']}ï¼‰")
    return len(problems) > 0, problems

# ========== ä¸»ç¨‹åº ==========
def main():
    input_file = "å¯¼å‡º#SKU_2025_07_31_17_20_52.csv"
    output_file = "é—®é¢˜skuæŠ¥å‘Š.csv"
    problematic_skus = []

    with open(input_file, newline='', encoding='utf-8-sig') as csvfile:
        reader = csv.DictReader(csvfile)
        print("\nğŸ“‹ æ£€æµ‹åˆ°CSVåˆ—åï¼š", reader.fieldnames)

        required_fields = ["äº§å“ID", "å¹³å°SKU", "åº—é“ºåç§°", "æœ¬åœ°å±•ç¤ºä»·"]
        for field in required_fields:
            if field not in reader.fieldnames:
                raise KeyError(f"âŒ ç¼ºå°‘å­—æ®µï¼š'{field}'ï¼Œè¯·ç¡®è®¤åˆ—åæ˜¯å¦å®Œå…¨ä¸€è‡´")

        for idx, row in enumerate(reader, 1):
            platform_sku = row["å¹³å°SKU"]
            product_id = row["äº§å“ID"]
            shop_name = row["åº—é“ºåç§°"]
            local_price = row["æœ¬åœ°å±•ç¤ºä»·"]
            url = f"https://www.amazon.com/dp/{platform_sku}"

            proxy = random.choice(PROXIES) if PROXIES else None
            fetched_info = get_amazon_product_info(url, proxy)
            has_problem, reasons = is_problematic(row, fetched_info)

            # æ‰“å°è¯¦ç»†æŠ“å–æ—¥å¿—
            status = "âŒ æœ‰é—®é¢˜" if has_problem else "âœ… æ­£å¸¸"
            print(f"\n[{idx}] {status} - SKU: {platform_sku}")
            if has_problem:
                print("  â¤ åŸå› : " + "ï¼›".join(reasons))
            print(f"  â¤ ä»·æ ¼: {fetched_info['ä»·æ ¼']}")
            print(f"  â¤ åº“å­˜: {fetched_info['åº“å­˜æƒ…å†µ']}")
            print(f"  â¤ åˆ°è´§: {fetched_info['é¢„è®¡åˆ°è´§']}")

            if has_problem:
                problematic_skus.append({
                    "SKU": platform_sku,
                    "äº§å“ID": product_id,
                    "åº—é“ºåç§°": shop_name,
                    "ä»·æ ¼": fetched_info["ä»·æ ¼"],
                    "åº“å­˜æƒ…å†µ": fetched_info["åº“å­˜æƒ…å†µ"],
                    "é¢„è®¡åˆ°è´§": fetched_info["é¢„è®¡åˆ°è´§"],
                    "æœ¬åœ°å±•ç¤ºä»·": local_price,
                    "é—®é¢˜åŸå› ": "ï¼›".join(reasons)
                })

            time.sleep(random.uniform(3, 7))  # é¿å…é£æ§

    if problematic_skus:
        with open(output_file, "w", newline='', encoding='utf-8-sig') as outcsv:
            writer = csv.DictWriter(outcsv, fieldnames=problematic_skus[0].keys())
            writer.writeheader()
            writer.writerows(problematic_skus)
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆï¼š{output_file}")
    else:
        print("\nâœ… æ²¡æœ‰å‘ç°é—®é¢˜SKUã€‚")

if __name__ == "__main__":
    main()
